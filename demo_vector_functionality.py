#!/usr/bin/env python3
"""
OnboardAI Vector Functionality Demo
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏—Ö –∑–Ω–∞–Ω—å —Ç–∞ AI-–ø–æ–º—ñ—á–Ω–∏–∫–∞
"""

import asyncio
import json
import httpx
from typing import Dict, List

class OnboardAIVectorDemo:
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ–π–Ω–∏–π –∫–ª–∞—Å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π OnboardAI"""
    
    def __init__(self, api_base_url: str = "http://localhost:8000"):
        self.api_base_url = api_base_url
        self.client = httpx.AsyncClient(timeout=30.0)
        
    async def check_system_status(self) -> Dict:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–≥–∞–ª—å–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å—É —Å–∏—Å—Ç–µ–º–∏"""
        print("ü©∫ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å—É —Å–∏—Å—Ç–µ–º–∏...")
        
        try:
            response = await self.client.get(f"{self.api_base_url}/health")
            status = response.json()
            
            print(f"‚úÖ –°—Ç–∞—Ç—É—Å –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–µ—Ä–≤—ñ—Å—É: {status['status']}")
            print(f"üóÑÔ∏è Supabase: {status['supabase']}")
            print(f"‚ö° Redis: {status['redis']}")
            
            return status
            
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å—É: {e}")
            return {"error": str(e)}
    
    async def check_vector_service_status(self) -> Dict:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Å–µ—Ä–≤—ñ—Å—É"""
        print("\nüß† –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Å–µ—Ä–≤—ñ—Å—É...")
        
        try:
            response = await self.client.get(f"{self.api_base_url}/api/v1/vectorization/status")
            status = response.json()
            
            if "vector_service_configured" in status:
                print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∏–π —Å–µ—Ä–≤—ñ—Å –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–∏–π: {status['vector_service_configured']}")
                
                if status.get("status") == "ready":
                    if status.get("total_vectors", 0) > 0:
                        print(f"üéØ Total vectors: {status['total_vectors']}")
                        print(f"üìè Dimension: {status['dimension']}")
                    else:
                        print("‚ö†Ô∏è –í–µ–∫—Ç–æ—Ä–Ω–∞ –±–∞–∑–∞ –ø–æ—Ä–æ–∂–Ω—è")
                elif status.get("status") == "unavailable":
                    print("‚ö†Ô∏è –í–µ–∫—Ç–æ—Ä–Ω–∏–π —Å–µ—Ä–≤—ñ—Å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π (–ø–æ—Ç—Ä—ñ–±–Ω–æ –Ω–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏ –∫–ª—é—á—ñ)")
            else:
                print("‚ùå –í–µ–∫—Ç–æ—Ä–Ω–∏–π —Å–µ—Ä–≤—ñ—Å –Ω–µ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–∏–π")
            
            return status
            
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Å–µ—Ä–≤—ñ—Å—É: {e}")
            return {"error": str(e)}
    
    async def start_vectorization_process(self) -> Dict:
        """–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—É –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó (DEMO –≤–µ—Ä—Å—ñ—è - –±–µ–∑ —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö)"""
        print("\nüöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—É –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏—Ö –∑–Ω–∞–Ω—å...")
        print("üìù –¶–µ DEMO –≤–µ—Ä—Å—ñ—è - –¥–ª—è –ø–æ–≤–Ω–æ—ó —Ä–æ–±–æ—Ç–∏ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –∫–ª—é—á—ñ OpenAI —Ç–∞ Pinecone")
        
        try:
            # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è —Ç–æ–≥–æ, —â–æ –±—É–¥–µ –≤—ñ–¥–±—É–≤–∞—Ç–∏—Å—è
            print("\nüìã –ï—Ç–∞–ø–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó:")
            print("1. üîç –ê–Ω–∞–ª—ñ–∑ Supabase —Å—Ö–µ–º–∏ DocuMinds")
            print("2. üìö –í–∏—Ç—è–≥–Ω–µ–Ω–Ω—è –æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ–π, —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ–π —Ç–∞ —Ä–µ—Å—É—Ä—Å—ñ–≤")
            print("3. ‚úÇÔ∏è –†–æ–∑–±–∏–≤–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç—É –Ω–∞ chunks (1000 —Å–∏–º–≤–æ–ª—ñ–≤)")
            print("4. üß† –°—Ç–≤–æ—Ä–µ–Ω–Ω—è embeddings —á–µ—Ä–µ–∑ OpenAI text-embedding-3-large")
            print("5. üóÑÔ∏è –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä—ñ–≤ –≤ Pinecone (3072 —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ)")
            print("6. ‚úÖ –ì–æ—Ç–æ–≤–æ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É!")
            
            demo_result = {
                "success": True,
                "message": "–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è –ø—Ä–æ—Ü–µ—Å—É –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó –∑–∞–≤–µ—Ä—à–µ–Ω–∞",
                "demo_mode": True,
                "would_process": {
                    "organizations": "–î–æ–º–µ–Ω companies, –ø–ª–∞–Ω —Ç–∞ —Å—Ç–∞—Ç—É—Å",
                    "integrations": "Notion, Jira, Confluence –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è",
                    "resources": "–î–æ–∫—É–º–µ–Ω—Ç–∏, —Ç–∞–±–ª–∏—Ü—ñ, —Å—Ç—Ä–∞–Ω—ñ—á–∫–∏",
                    "knowledge_base": "–ë–∞–∑–æ–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è —Ç–∞ –ø—Ä–æ—Ü–µ—Å–∏"
                },
                "estimated_chunks": "50-200 chunks",
                "estimated_vectors": "3072 —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ –∫–æ–∂–µ–Ω",
                "storage": "Pinecone vector database"
            }
            
            return demo_result
            
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó: {e}")
            return {"error": str(e)}
    
    async def demo_semantic_search(self) -> Dict:
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É"""
        print("\nüîç –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É...")
        
        demo_queries = [
            "—è–∫ —Ä–æ–∑–ø–æ—á–∞—Ç–∏ —Ä–æ–±–æ—Ç—É —è–∫ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ —Ä–æ–∑—Ä–æ–±–Ω–∏–∫",
            "–ø—Ä–æ—Ü–µ—Å –∫–æ–¥ —Ä–µ–≤'—é –≤ –∫–æ–º–ø–∞–Ω—ñ—ó",
            "—Ç–µ—Ö–Ω—ñ—á–Ω–∏–π —Å—Ç–µ–∫ –¥–ª—è backend —Ä–æ–∑—Ä–æ–±–∫–∏",
            "—ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ notion —Ç–∞ jira"
        ]
        
        results = []
        
        for query in demo_queries:
            print(f"\nüîé –ó–∞–ø–∏—Ç: '{query}'")
            
            try:
                # –°–∏–º—É–ª—è—Ü—ñ—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É
                demo_result = {
                    "query": query,
                    "semantic_results": [
                        {
                            "content": f"–í—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∑–∞–ø–∏—Ç—É '{query}' –∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ—ó –±–∞–∑–∏ –∑–Ω–∞–Ω—å",
                            "similarity_score": 0.85,
                            "source": "company_documentation",
                            "type": "onboarding_guide"
                        },
                        {
                            "content": f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø—Ä–æ—Ü–µ—Å–∏ –¥–ª—è '{query}'",
                            "similarity_score": 0.72,
                            "source": "internal_wiki",
                            "type": "process_documentation"
                        }
                    ],
                    "search_type": "semantic_vector",
                    "confidence": "high"
                }
                
                results.append(demo_result)
                print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(demo_result['semantic_results'])} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
                
            except Exception as e:
                print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É: {e}")
        
        return {
            "success": True,
            "demo_queries": len(demo_queries),
            "total_results": sum(len(r.get("semantic_results", [])) for r in results),
            "example_results": results
        }
    
    async def demo_ai_assistant(self) -> Dict:
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è AI-–ø–æ–º—ñ—á–Ω–∏–∫–∞"""
        print("\nü§ñ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è AI-–ø–æ–º—ñ—á–Ω–∏–∫–∞ –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–∏–º–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—è–º–∏...")
        
        demo_questions = [
            {
                "question": "–Ø–∫ —Ä–æ–∑–ø–æ—á–∞—Ç–∏ —Ä–æ–±–æ—Ç—É —è–∫ Frontend Developer?",
                "role": "Frontend Developer",
                "expected_response": "–î–µ—Ç–∞–ª—å–Ω–∏–π –ø–ª–∞–Ω –ø–µ—Ä—à–æ–≥–æ —Ç–∏–∂–Ω—è –∑ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è–º —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞"
            },
            {
                "question": "–©–æ —Ç–∞–∫–µ –∫–æ–¥ —Å—Ç–∞–π–ª –≤ –Ω–∞—à—ñ–π –∫–æ–º–ø–∞–Ω—ñ—ó?",
                "role": "general",
                "expected_response": "–ì–∞–π–¥–ª–∞–π–Ω –∑ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è, –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–æ—é —Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ—é –∫–æ–¥—É"
            },
            {
                "question": "–Ø–∫—ñ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ñ –º–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –¥–ª—è –¥–µ–ø–ª–æ—é?",
                "role": "DevOps Engineer",
                "expected_response": "Docker, Kubernetes, AWS –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è —Ç–∞ CI/CD"
            }
        ]
        
        ai_responses = []
        
        for qa in demo_questions:
            print(f"\n‚ùì –ü–∏—Ç–∞–Ω–Ω—è: {qa['question']}")
            print(f"üë§ –†–æ–ª—å: {qa['role']}")
            
            try:
                # –°–∏–º—É–ª—è—Ü—ñ—è AI –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ—à—É–∫—É
                demo_response = {
                    "question": qa["question"],
                    "role_context": qa["role"],
                    "ai_answer": f"""
ü§ñ AI-–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º:

{qa['expected_response']}

**–ê–ª–≥–æ—Ä–∏—Ç–º –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó:**
1. üîç –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫ –ø–æ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ñ–π –±–∞–∑—ñ –∑–Ω–∞–Ω—å
2. üìö –í–∏—Ç—è–≥–Ω–µ–Ω–Ω—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö chunks –∑ Pinecone  
3. üß† –ê–Ω–∞–ª—ñ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –∑ GPT-3.5-turbo
4. üìù –§–æ—Ä–º—É–ª—é–≤–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–æ –¥–ª—è —Ä–æ–ª—ñ "{qa['role']}"
5. üìä –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä—ñ–≤–Ω—è –¥–æ–≤—ñ—Ä–∏ —Ç–∞ –¥–∂–µ—Ä–µ–ª

**–ü–µ—Ä–µ–≤–∞–≥–∏ –ø–µ—Ä–µ–¥ –æ–±—ã—á–Ω–∏–º–∏ Q&A:**
‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –∑–∞–º—ñ—Å—Ç—å —à–∞–±–ª–æ–Ω–Ω–∏—Ö
‚úÖ –í—Ä–∞—Ö—É–≤–∞–Ω–Ω—è —Ä–æ–ª—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
‚úÖ –ü–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –¥–∂–µ—Ä–µ–ª–∞
‚úÖ –©–æ–¥–µ–Ω–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —á–µ—Ä–µ–∑ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ Supabase
                    """,
                    "confidence": 0.88,
                    "context_found": True,
                    "sources": [
                        {"source": "company_onboarding_guide", "relevance": 0.92},
                        {"source": "team_processes", "relevance": 0.85},
                        {"source": "tech_documentation", "relevance": 0.78}
                    ],
                    "ai_model": "GPT-3.5-turbo + Semantic Search",
                    "vector_search_performed": True
                }
                
                ai_responses.append(demo_response)
                print(f"‚úÖ AI –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∞ (–¥–æ–≤—ñ—Ä–∞: {demo_response['confidence']:.1%})")
                
            except Exception as e:
                print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó AI –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {e}")
        
        return {
            "success": True,
            "total_questions": len(demo_questions),
            "ai_responses": ai_responses,
            "demo_features": [
                "–°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏—Ö –∑–Ω–∞–Ω—å",
                "–ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑ AI",
                "–í—Ä–∞—Ö—É–≤–∞–Ω–Ω—è —Ä–æ–ª—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞",
                "–í–∫–∞–∑–∞–Ω–Ω—è –¥–∂–µ—Ä–µ–ª —Ç–∞ –¥–æ–≤—ñ—Ä–∏",
                "–Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ DocuMinds —Ç–∞ Notion"
            ]
        }
    
    async def demo_knowledge_integration(self) -> Dict:
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó –∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏"""
        print("\nüîó –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó –∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏...")
        
        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è DocuMinds —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó
        print("\nüìã DocuMinds Integration:")
        try:
            response = await self.client.get(
                f"{self.api_base_url}/api/v1/documinds/resources",
                params={
                    "organization_domain": "demo.com",
                    "integration_type": "notion",
                    "limit": 5
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                print(f"‚úÖ DocuMinds —Ä–µ—Å—É—Ä—Å–∏: {data.get('resources_count', 0)} –∑–Ω–∞–π–¥–µ–Ω–æ")
            else:
                print("‚ö†Ô∏è DocuMinds —Ä–µ—Å—É—Ä—Å–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ (–ø–æ—Ä–æ–∂–Ω—è –±–∞–∑–∞)")
                
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ DocuMinds: {e}")
        
        # –°–∏–º—É–ª—è—Ü—ñ—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó  
        demo_integration = {
            "documinds_extraction": {
                "organizations": "–î–æ–º–µ–Ω companies —Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏",
                "integrations": "–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Notion, Jira, Confluence", 
                "resources": "–î–æ–∫—É–º–µ–Ω—Ç–∏ —Ç–∞ —Å—Ç—Ä–∞–Ω—ñ—á–∫–∏ –∫–æ–ª–∏–¥–∂—É",
                "groups_permissions": "–ü—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø—É —Ç–∞ —Ä–æ–ª—ñ"
            },
            "vectorization_plan": [
                "üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–∞–Ω—ñ Supabase —Å—Ö–µ–º–∏",
                "‚úÇÔ∏è Text chunking (1000 —Å–∏–º–≤/100 overlap)",
                "üß† OpenAI embeddings (text-embedding-3-large)",
                "üóÑÔ∏è Pinecone vector storage",
                "üîÑ Auto-reindex –ø—Ä–∏ –∑–º—ñ–Ω–∞—Ö"
            ],
            "search_capabilities": [
                "üéØ –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫ –∑–∞ –∑–º—ñ—Å—Ç–æ–º",
                "üè¢ –ü–æ—à—É–∫ –ø–æ –æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—ó",
                "üë§ –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü—ñ—è –ø–æ —Ä–æ–ª—è—Ö",
                "üìÖ –ß–∞—Å–æ–≤—ñ –∑–º—ñ–Ω–∏ —Ç–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ñ—Å—Ç—å",
                "üîç –•—Ä–µ—Å—Ç-—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∏ –º—ñ–∂ —Å–∏—Å—Ç–µ–º–∞–º–∏"
            ]
        }
        
        print("\nüéØ –ú–æ–∂–ª–∏–≤–æ—Å—Ç—ñ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó:")
        for category, items in demo_integration.items():
            print(f"\n{category.replace('_', ' ').title()}:")
            if isinstance(items, list):
                for item in items:
                    print(f"  {item}")
            else:
                for key, value in items.items():
                    print(f"  {key}: {value}")
        
        return demo_integration
    
    async def run_full_demo(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–≤–Ω–æ—ó –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó –≤–µ–∫—Ç–æ—Ä–Ω–∏—Ö –º–æ–∂–ª–∏–≤–æ—Å—Ç–µ–π"""
        print("üöÄ OnboardAI Vector Functionality Demo")
        print("=" * 50)
        
        # 1. –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º–∏
        await self.check_system_status()
        
        # 2. –í–µ–∫—Ç–æ—Ä–Ω–∏–π —Å–µ—Ä–≤—ñ—Å 
        await self.check_vector_service_status()
        
        # 3. –ü—Ä–æ—Ü–µ—Å –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó
        await self.start_vectorization_process()
        
        # 4. –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫
        await self.demo_semantic_search()
        
        # 5. AI-–ø–æ–º—ñ—á–Ω–∏–∫
        await self.demo_ai_assistant()
        
        # 6. –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è
        await self.demo_knowledge_integration()
        
        print("\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print("\nüìã –ù–∞—Å—Ç—É–ø–Ω—ñ –∫—Ä–æ–∫–∏ –¥–ª—è production:")
        print("1. üîë –ù–∞–ª–∞—à—Ç—É–π—Ç–µ OPENAI_API_KEY")
        print("2. üóÑÔ∏è –ù–∞–ª–∞—à—Ç—É–π—Ç–µ PINECONE_API_KEY")
        print("3. üìö –ó–∞–ø—É—Å—Ç—ñ—Ç—å /api/v1/vectorization/start")
        print("4. ü§ñ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ /api/v1/ai/contextual-answer")
        print("5. üîç –¢–µ—Å—Ç—É–π—Ç–µ /api/v1/vectorization/semantic-search")
        
        await self.client.aclose()

async def main():
    """–ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó"""
    demo = OnboardAIVectorDemo()
    await demo.run_full_demo()

if __name__ == "__main__":
    asyncio.run(main())
